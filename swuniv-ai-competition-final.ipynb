{"cells":[{"cell_type":"markdown","metadata":{},"source":["# SW중심대학 공동 AI 경진대회 <본선>"]},{"cell_type":"markdown","metadata":{},"source":["1. 평가 산식\n","\n","> - Accuracy (정확도)\n","\n","2. 본선 평가\n","\n","![](https://dacon.s3.ap-northeast-2.amazonaws.com/competition/235970/editor-image/166138683752218.jpeg)\n","\n","3. 개인 또는 팀 참여 규칙\n","\n","> - 본선 진출자는 예선과 동일한 팀원 및 팀명으로 참가해야 함\n","> - 본선 진출자 전원은 9/16(금)까지 재학증명서 또는 휴학증명서를 dacon@dacon.io 메일로 제출하야 함 [링크]\n","> ※ 허위 참가사실이 확인되거나 혹은 기간내 서류 제출을 하지 않을 시, 소속 팀 전체가 대회 탈락 처리됨을 유의 부탁드립니다.\n","> ※ 또한, 대회 기간 도중 팀원 중 졸업생 신분의 참가자가 포함되어있는 것이 확인될 경우에도 해당 팀 전체가 대회 탈락 처리됩니다.\n","\n"," \n","\n","4. 외부 데이터 및 사전 학습 모델 사용\n","\n","> - 비상업적 용도로 사용할 수 있는 외부 데이터 사용 가능\n","> - 사용에 문제가 없는 사전 학습 모델(Pre-trained Model) 사용 가능\n","\n","\n","5. 유의 사항\n","\n","> - 1일 최대 제출 횟수: 3회\n","> - 사용 가능 언어: Python, R\n","> - 모델 학습에서 평가 데이터셋(Test Dataset) 활용(Data Leakage) 시 실격 처리 됨 (참조 : 링크)\n","> - 답안을 수기로 작성하는 경우 실격 처리 됨\n","> - 다른 팀과의 아이디어 또는 코드 쉐어링이 의심되는 경우 데이콘에서 코드를 요청할 수 있으며, 기간 내 코드를 제출하지 않거나 치팅이 확인되는 경우 실격 처리 됨\n","> - 재학/휴학 증명서, 발표 자료 및 코드를 요청한 일자에 제출하지 않은 경우 실격 처리 됨\n","> - 최종 순위는 선택된 파일 중에서 채점되므로 참가자는 제출 창에서 자신이 최종적으로 채점을 받고 싶은 파일을 선택해야 함\n","> - 소프트웨어중심대학 공동 AI 경진대회 추진위원회는 대회 참가팀의 부정 행위를 금지하고 있으며, 이와 관련하여 본 경기를 위탁 운영하는 데이콘의 다른 경진대회에서 부정 제출 이력이 있는 경우에는 평가가 제한됩니다.\n","> - 자세한 사항은 아래의 링크를 참고해 주시기 바랍니다. https://dacon.io/notice/notice/13\n","\n","6. 토론(질문)\n","\n","> - 대회 운영 및 데이터 이상에 관련된 질문 외에는 답변을 드리지 않습니다.\n","> - 기타 질문은 토론 페이지를 통해 자유롭게 토론해주시기 바랍니다.\n","> - 소프트웨어중심대학 공동 AI 경진대회 추진위원회의 답변을 희망하시는 경우에는 토크 게시판의 대회 문의 게시글에 댓글을 달아주시면 검토하여 답변을 드리겠습니다.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 모듈 및 설정"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing modules for handwritten text generation.\n"]}],"source":["import os\n","import cv2\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from jamo import h2j, j2hcj\n","from join_jamos import join_jamos\n","from trdg.generators import GeneratorFromStrings\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":200,"metadata":{},"outputs":[],"source":["def save_gt(filename, img_path_list, text_list):\n","    with open(filename, 'w', encoding='utf-8') as f:\n","        for img_path, text in zip(img_path_list, text_list):\n","            f.write(f'{img_path}\\t{j2hcj(h2j(text))}\\n')"]},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[],"source":["def data_generate(char, fonts_list, count=1, orientation=0):\n","    lengths = np.random.randint(1, 10, count)\n","    strings = [''.join(list(np.random.choice(char, length))) for length in lengths]\n","    fonts = np.random.choice(fonts_list, count)\n","    size = int(np.random.normal(300, 50))\n","    blur = np.random.choice([True, False])\n","    background_type = np.random.choice([0, 1, 2])\n","    distorsion_type = np.random.choice([0, 1, 2, 3])\n","    distorsion_orientation = np.random.choice([0, 1, 2])\n","    text_color = f'#{np.random.randint(0, 256):02X}{np.random.randint(0, 256):02X}{np.random.randint(0, 256):02X}'\n","    character_spacing = np.random.randint(0, 20) * np.random.randint(0, 20)\n","    skewing_angle = int((400 - character_spacing) * 45 / 400)\n","    margins = (\n","        size * np.random.randint(-5, 15) // 100,\n","        size * np.random.randint(-5, 15) // 100,\n","        size * np.random.randint(-5, 15) // 100,\n","        size * np.random.randint(-5, 15) // 100\n","    )\n","    stroke_width = np.random.choice([0, 0, 0, 3, 6])\n","    stroke_fill = f'#{np.random.randint(0, 256):02X}{np.random.randint(0, 256):02X}{np.random.randint(0, 256):02X}'\n","\n","    generator = GeneratorFromStrings(\n","        strings,\n","        fonts=fonts,\n","        count=count,\n","        language='ko',\n","        size=size,\n","        skewing_angle=skewing_angle,\n","        random_skew=True,\n","        blur=blur,\n","        background_type=background_type,\n","        distorsion_type=distorsion_type,\n","        distorsion_orientation=distorsion_orientation,\n","        text_color=text_color,\n","        orientation=orientation,\n","        character_spacing=character_spacing,\n","        margins=margins,\n","        stroke_width=stroke_width,\n","        stroke_fill=stroke_fill,\n","    )\n","\n","    img_list = []\n","    lbl_list = []\n","\n","    for img, lbl in generator:\n","        img_list.append(np.array(img))\n","        lbl_list.append(lbl)\n","\n","    return img_list, lbl_list"]},{"cell_type":"markdown","metadata":{},"source":["## 데이터"]},{"cell_type":"markdown","metadata":{},"source":["### 폴더 및 파일명"]},{"cell_type":"code","execution_count":192,"metadata":{},"outputs":[],"source":["inputs = 'inputs'\n","outputs = 'outputs'\n","processing = 'processing'\n","\n","train_csv = 'train.csv'\n","test_csv = 'test.csv'\n","submission_csv = 'sample_submission.csv'\n","\n","separation = 'separation'\n","lmdb = 'lmdb'\n","generate = 'generate'\n","\n","horizontal = 'horizontal'\n","vertical = 'vertical'\n","\n","train_gt = 'train_gt.txt'\n","test_gt = 'test_gt.txt'\n","training_gt = 'training_gt.txt'\n","validation_gt = 'validation_gt.txt'\n","generate_gt = 'generate_gt.txt'"]},{"cell_type":"markdown","metadata":{},"source":["### CSV 파일 가져오기"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"lMkIu2_SJm0W"},"outputs":[],"source":["train = pd.read_csv(os.path.join(inputs, train_csv))\n","test = pd.read_csv(os.path.join(inputs, test_csv))\n","submission = pd.read_csv(os.path.join(outputs, submission_csv))"]},{"cell_type":"markdown","metadata":{},"source":["### 새로운 텍스트 생성"]},{"cell_type":"code","execution_count":201,"metadata":{},"outputs":[],"source":["first = [*'ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ']\n","middle = [*'ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ']\n","last = [''] + [*'ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ']\n","\n","ko = [join_jamos(f'{f}{m}{l}') for f in first for m in middle for l in last]\n","fonts_list = list(map(lambda x : os.path.join('trdg/fonts/ko/', x), os.listdir('trdg/fonts/ko/')))"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [2:53:11<00:00,  1.04s/it] \n"]}],"source":["img_list, lbl_list = [], []\n","img_path_list, text_list = [], []\n","idx = 0\n","\n","for _ in tqdm(range(10000)):\n","    img_tmp, lbl_tmp = data_generate(ko, fonts_list, orientation=1)\n","\n","    for img, lbl in zip(img_tmp, lbl_tmp):\n","        img_path = f'./{generate}/{idx:06d}.png'\n","        if img.ndim != 0:\n","            os.makedirs(os.path.dirname(os.path.join(processing, generate, horizontal, img_path)), exist_ok = True)\n","            cv2.imwrite(os.path.join(processing, generate, horizontal, img_path), cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n","            img_path_list.append(img_path)\n","            text_list.append(lbl)\n","            idx = idx + 1\n","    \n","save_gt(os.path.join(processing, generate, horizontal, generate_gt), img_path_list, text_list)"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [2:25:30<00:00,  1.15it/s] \n"]}],"source":["img_list, lbl_list = [], []\n","img_path_list, text_list = [], []\n","idx = 0\n","\n","for _ in tqdm(range(10000)):\n","    img_tmp, lbl_tmp = data_generate(ko, fonts_list, orientation=0)\n","\n","    for img, lbl in zip(img_tmp, lbl_tmp):\n","        img_path = f'./{generate}/{idx:06d}.png'\n","        if img.ndim != 0:\n","            os.makedirs(os.path.dirname(os.path.join(processing, generate, vertical, img_path)), exist_ok = True)\n","            cv2.imwrite(os.path.join(processing, generate, vertical, img_path), img)\n","            img_path_list.append(img_path)\n","            text_list.append(lbl)\n","            idx = idx + 1\n","    \n","save_gt(os.path.join(processing, generate, vertical, generate_gt), img_path_list, text_list)"]},{"cell_type":"markdown","metadata":{},"source":["### 모델 튜닝 및 최종 학습 데이터셋 생성"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["horizontal_img_path = []\n","horizontal_text = []\n","vertical_img_path = []\n","vertical_text = []\n","\n","for img_path, text in zip(train['img_path'], train['text']):\n","    img = cv2.imread(os.path.join(inputs, img_path))\n","    height, weight, color = img.shape\n","    if height > weight:\n","        os.makedirs(os.path.dirname(os.path.join(processing, separation, horizontal, img_path)), exist_ok = True)\n","        cv2.imwrite(os.path.join(processing, separation, horizontal, img_path), cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n","        horizontal_img_path.append(img_path)\n","        horizontal_text.append(text)\n","    else: \n","        os.makedirs(os.path.dirname(os.path.join(processing, separation, vertical, img_path)), exist_ok = True)\n","        cv2.imwrite(os.path.join(processing, separation, vertical, img_path), img)\n","        vertical_img_path.append(img_path)\n","        vertical_text.append(text)\n","\n","# Horizontal\n","save_gt(os.path.join(processing, separation, horizontal, train_gt), horizontal_img_path, horizontal_text)\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(horizontal_img_path, horizontal_text, test_size=0.2)\n","\n","save_gt(os.path.join(processing, separation, horizontal, training_gt), X_train, y_train)\n","save_gt(os.path.join(processing, separation, horizontal, validation_gt), X_valid, y_valid)\n","\n","# Vertical\n","save_gt(os.path.join(processing, separation, vertical, train_gt), vertical_img_path, vertical_text)\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(vertical_img_path, vertical_text, test_size=0.2)\n","\n","save_gt(os.path.join(processing, separation, vertical, training_gt), X_train, y_train)\n","save_gt(os.path.join(processing, separation, vertical, validation_gt), X_valid, y_valid)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 최종 예측 데이터셋 생성"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["horizontal_img_path = []\n","vertical_img_path = []\n","\n","for img_path in test['img_path']:\n","    img = cv2.imread(os.path.join(inputs, img_path))\n","    height, weight, color = img.shape\n","    if height > weight:\n","        os.makedirs(os.path.dirname(os.path.join(processing, separation, horizontal, img_path)), exist_ok = True)\n","        cv2.imwrite(os.path.join(processing, separation, horizontal, img_path), cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE))\n","        horizontal_img_path.append(img_path)\n","    else:\n","        os.makedirs(os.path.dirname(os.path.join(processing, separation, vertical, img_path)), exist_ok = True)\n","        cv2.imwrite(os.path.join(processing, separation, vertical, img_path), img)\n","        vertical_img_path.append(img_path)\n","\n","horizontal_text = ['예측' for _ in range(len(horizontal_img_path))]\n","vertical_text = ['예측' for _ in range(len(vertical_img_path))]\n","\n","# Horizontal\n","save_gt(os.path.join(processing, separation, horizontal, test_gt), horizontal_img_path, horizontal_text)\n","\n","# Vertical\n","save_gt(os.path.join(processing, separation, vertical, test_gt), vertical_img_path, vertical_text)"]},{"cell_type":"markdown","metadata":{},"source":["### LMDB 데이터셋 생성"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 1985\n","Created dataset with 1985 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/horizontal --gtFile processing/separation/horizontal/train_gt.txt --outputPath processing/lmdb/horizontal/train"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 10174\n","Written 2000 / 10174\n","Written 3000 / 10174\n","Written 4000 / 10174\n","Written 5000 / 10174\n","Written 6000 / 10174\n","Written 7000 / 10174\n","Written 8000 / 10174\n","Written 9000 / 10174\n","Written 10000 / 10174\n","Created dataset with 10174 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/vertical --gtFile processing/separation/vertical/train_gt.txt --outputPath processing/lmdb/vertical/train"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Created dataset with 445 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/horizontal --gtFile processing/separation/horizontal/test_gt.txt --outputPath processing/lmdb/horizontal/test"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 3224\n","Written 2000 / 3224\n","Written 3000 / 3224\n","Created dataset with 3224 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/vertical --gtFile processing/separation/vertical/test_gt.txt --outputPath processing/lmdb/vertical/test"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 1588\n","Created dataset with 1588 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/horizontal --gtFile processing/separation/horizontal/training_gt.txt --outputPath processing/lmdb/horizontal/training"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 8139\n","Written 2000 / 8139\n","Written 3000 / 8139\n","Written 4000 / 8139\n","Written 5000 / 8139\n","Written 6000 / 8139\n","Written 7000 / 8139\n","Written 8000 / 8139\n","Created dataset with 8139 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/vertical --gtFile processing/separation/vertical/training_gt.txt --outputPath processing/lmdb/vertical/training"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Created dataset with 397 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/horizontal --gtFile processing/separation/horizontal/validation_gt.txt --outputPath processing/lmdb/horizontal/validation"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 2035\n","Written 2000 / 2035\n","Created dataset with 2035 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/separation/vertical --gtFile processing/separation/vertical/validation_gt.txt --outputPath processing/lmdb/vertical/validation"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 9403\n","Written 2000 / 9403\n","Written 3000 / 9403\n","Written 4000 / 9403\n","Written 5000 / 9403\n","Written 6000 / 9403\n","Written 7000 / 9403\n","Written 8000 / 9403\n","Written 9000 / 9403\n","Created dataset with 9403 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/generate/horizontal --gtFile processing/generate/horizontal/generate_gt.txt --outputPath processing/lmdb/horizontal/generate"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Written 1000 / 9419\n","Written 2000 / 9419\n","Written 3000 / 9419\n","Written 4000 / 9419\n","Written 5000 / 9419\n","Written 6000 / 9419\n","Written 7000 / 9419\n","Written 8000 / 9419\n","Written 9000 / 9419\n","Created dataset with 9419 samples\n"]}],"source":["!python deep_text_recognition_benchmark/create_lmdb_dataset.py --inputPath processing/generate/vertical --gtFile processing/generate/vertical/generate_gt.txt --outputPath processing/lmdb/vertical/generate"]},{"cell_type":"markdown","metadata":{},"source":["## 모델"]},{"cell_type":"markdown","metadata":{},"source":["### deep_text_recognition_benchmark"]},{"cell_type":"markdown","metadata":{},"source":["아래의 명령어를 실행해 수평 / 수직 방향에 대한 간판이미지를 따로 학습   \n","(메모리 누수 문제로 인해서 Jupyter notebook 안에서 실행하지 않음)"]},{"cell_type":"markdown","metadata":{},"source":["python deep_text_recognition_benchmark/train.py --train_data processing/lmdb/horizontal/ --select_data training-generate --batch_ratio 0.5-0.5 --valid_data processing/lmdb/horizontal/validation --batch_size 20 --manualSeed 16 --imgH 64 --imgW 256 --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --num_fiducial 20 --output_channel 1024 --hidden_size 1024"]},{"cell_type":"markdown","metadata":{},"source":["python deep_text_recognition_benchmark/train.py --train_data processing/lmdb/horizontal/ --select_data training-generate --batch_ratio 0.5-0.5 --valid_data processing/lmdb/vertical/validation --batch_size 20 --manualSeed 15 --imgH 64 --imgW 256 --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --num_fiducial 20 --output_channel 1024 --hidden_size 1024"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNVQGUixdlplqu5lgtWTq5z","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.7.13 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"240bc028caeb8b02ff80d8aedfc61caf7a0e4db2770780d40c5b717508bae340"}}},"nbformat":4,"nbformat_minor":0}
